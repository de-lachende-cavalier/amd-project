- [x] make sure that the data preparation pipeline worked as intended (by inspecting the various pieces)
- [ ] proceed as in Chollet (i.e. bag-of-words => TF-IDF => transformers)
    - [x] bag of words with 1 gram
    - [x] bag of words with 2 gram and TF-IDF
    - [ ] once that's done try different architectures, models, feature engineering (dimensionality reduction)
        - [x] feature engineering
            - [x] check feature importance
            - [x] ? the embedding 'attributes' thing
        - [ ] try RNNs (LSTM, GRU)
        - [ ] possibly transformers (training time might be excessive)
        - [ ] try transfer learning
- [ ] make the exposition more fluent (in jupyter notebook)
    - [ ] possibly split a single notebook into multiple ones?
- [ ] put everything on colab and make sure it works!
- [ ] write the report
